from typing import List, Optional
from pathlib import Path
import shutil
import uuid
from datetime import datetime

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Query, Form
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.orm import Session

from app.core.config import settings
from app.core.logging import app_logger
from app.core.database import get_db
from app.models.file import FileRecord
from app.schemas.file import FileCreate, FileResponse, FileUpdate
from app.services.file_service import FileService
from app.services.file_storage import LocalFileService
from app.utils.file_utils import get_file_type, validate_file_size, validate_file_type

router = APIRouter()

# ä¾èµ–æ³¨å…¥
def get_file_service(db: Session = Depends(get_db)):
    return FileService(db)

def get_storage_service():
    return LocalFileService()

@router.post("/upload", response_model=List[FileResponse])
async def upload_files(
    files: List[UploadFile] = File(...),
    stage: str = Form(...),
    project_id: Optional[str] = Form(None),
    tags: Optional[str] = Form(None),
    description: Optional[str] = Form(None),
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°MinIOå¹¶è®°å½•åˆ°æ•°æ®åº“
    """
    try:
        uploaded_files = []

        tags_list = tags.split(",") if tags else []
        
        for i, file in enumerate(files):
            app_logger.info(f"ğŸ”¥ å¤„ç†ç¬¬ {i+1} ä¸ªæ–‡ä»¶: {file.filename}, å¤§å°: {file.size}, ç±»å‹: {file.content_type}")
            
            # éªŒè¯æ–‡ä»¶
            app_logger.info(f"ğŸ”¥ å¼€å§‹éªŒè¯æ–‡ä»¶: {file.filename}")
            if not validate_file_size(file.size):
                app_logger.error(f"ğŸ”¥ æ–‡ä»¶å¤§å°éªŒè¯å¤±è´¥: {file.filename}, å¤§å°: {file.size}")
                raise HTTPException(
                    status_code=400,
                    detail=f"æ–‡ä»¶ {file.filename} å¤§å°è¶…è¿‡é™åˆ¶"
                )
            
            if not validate_file_type(file.filename):
                app_logger.error(f"ğŸ”¥ æ–‡ä»¶ç±»å‹éªŒè¯å¤±è´¥: {file.filename}")
                raise HTTPException(
                    status_code=400,
                    detail=f"æ–‡ä»¶ {file.filename} ç±»å‹ä¸æ”¯æŒ"
                )
            
            app_logger.info(f"ğŸ”¥ æ–‡ä»¶éªŒè¯é€šè¿‡: {file.filename}")
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            file_id = str(uuid.uuid4())
            file_extension = Path(file.filename).suffix
            stored_filename = f"{file_id}{file_extension}"
            
            app_logger.info(f"ğŸ”¥ ç”Ÿæˆå­˜å‚¨æ–‡ä»¶å: {stored_filename}")
            
            # ä¸Šä¼ åˆ°æœ¬åœ°å­˜å‚¨
            app_logger.info(f"ğŸ”¥ å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ°æœ¬åœ°å­˜å‚¨: {stored_filename}")
            try:
                object_name = await storage_service.upload_file(
                    file=file,
                    object_name=stored_filename
                )
                app_logger.info(f"ğŸ”¥ æ–‡ä»¶å­˜å‚¨æˆåŠŸ: {object_name}")
            except Exception as storage_error:
                app_logger.error(f"ğŸ”¥ æ–‡ä»¶å­˜å‚¨å¤±è´¥: {str(storage_error)}")
                raise
            
            # åˆ›å»ºæ–‡ä»¶è®°å½•
            app_logger.info(f"ğŸ”¥ å¼€å§‹åˆ›å»ºæ•°æ®åº“è®°å½•")
            try:
                file_create = FileCreate(
                    original_name=file.filename,
                    stored_name=stored_filename,
                    file_path=object_name,
                    file_size=file.size,
                    file_type=file.content_type,
                    project_id=project_id,
                    stage=stage,
                    tags=tags_list,
                    description=description,
                    uploaded_by="current_user"  # TODO: ä»è®¤è¯ä¸­è·å–
                )
                app_logger.info(f"ğŸ”¥ FileCreateå¯¹è±¡åˆ›å»ºæˆåŠŸ: {file_create}")
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                app_logger.info(f"ğŸ”¥ å¼€å§‹ä¿å­˜åˆ°æ•°æ®åº“")
                file_record = file_service.create_file(file_create)
                app_logger.info(f"ğŸ”¥ æ•°æ®åº“è®°å½•åˆ›å»ºæˆåŠŸ: {file_record.id}")
                
                uploaded_files.append(file_record)
                
                app_logger.info(f"ğŸ”¥ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file.filename} -> {stored_filename}")
                
                # ğŸš€ è‡ªåŠ¨æå–å†…å®¹å¹¶ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
                try:
                    app_logger.info(f"ğŸ¤– å¼€å§‹è‡ªåŠ¨æå–æ–‡ä»¶å†…å®¹: {file.filename}")
                    
                    # é‡æ–°è¯»å–æ–‡ä»¶æ•°æ®ç”¨äºå†…å®¹æå–
                    await file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    file_data = await file.read()
                    
                    # æå–æ–‡ä»¶å†…å®¹
                    content = await file_service.extract_content(file_data, file.content_type or "")
                    
                    if content and content.strip():
                        app_logger.info(f"ğŸ¤– å†…å®¹æå–æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                        
                        # æ›´æ–°æ–‡ä»¶å†…å®¹åˆ°æ•°æ®åº“
                        await file_service.update_file_content(file_record.id, content)
                        
                        # ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
                        if project_id:
                            from app.services.ai_service import ai_service
                            
                            metadata = {
                                "file_id": file_record.id,
                                "project_id": project_id,
                                "file_name": file.filename,
                                "file_type": file.content_type,
                                "stage": stage,
                                "tags": tags_list,
                                "upload_time": datetime.now().isoformat(),
                                "content_length": len(content)
                            }
                            
                            success = await ai_service.add_document_to_vector_db(
                                content=content,
                                file_id=file_record.id,
                                file_name=file.filename,
                                project_id=project_id,
                                metadata=metadata
                            )
                            
                            if success:
                                app_logger.info(f"ğŸ¤– æ–‡ä»¶å·²æˆåŠŸç´¢å¼•åˆ°å‘é‡æ•°æ®åº“: {file.filename}")
                                # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
                                file_service.mark_file_processed(file_record.id)
                            else:
                                app_logger.warning(f"ğŸ¤– æ–‡ä»¶ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {file.filename}")
                        else:
                            app_logger.info(f"ğŸ¤– æ— é¡¹ç›®IDï¼Œè·³è¿‡å‘é‡ç´¢å¼•: {file.filename}")
                    else:
                        app_logger.warning(f"ğŸ¤– æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æå–å¤±è´¥: {file.filename}")
                        
                except Exception as index_error:
                    app_logger.error(f"ğŸ¤– è‡ªåŠ¨ç´¢å¼•å¤±è´¥: {file.filename}, é”™è¯¯: {str(index_error)}")
                    # ç´¢å¼•å¤±è´¥ä¸å½±å“æ–‡ä»¶ä¸Šä¼ æˆåŠŸ
                
            except Exception as db_error:
                app_logger.error(f"ğŸ”¥ æ•°æ®åº“æ“ä½œå¤±è´¥: {str(db_error)}")
                raise
        
        app_logger.info(f"ğŸ”¥ æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œå…± {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        return uploaded_files
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ğŸ”¥ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        app_logger.error(f"ğŸ”¥ å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        import traceback
        app_logger.error(f"ğŸ”¥ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

@router.get("/", response_model=List[FileResponse])
async def list_files(
    project_id: Optional[str] = Query(None, description="é¡¹ç›®IDç­›é€‰"),
    stage: Optional[str] = Query(None, description="é¡¹ç›®é˜¶æ®µç­›é€‰"),
    tags: Optional[str] = Query(None, description="æ ‡ç­¾ç­›é€‰ï¼Œé€—å·åˆ†éš”"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    file_service: FileService = Depends(get_file_service)
):
    """
    è·å–æ–‡ä»¶åˆ—è¡¨
    """
    try:
        tags_list = tags.split(",") if tags else None
        
        files = file_service.get_files(
            project_id=project_id,
            stage=stage,
            tags=tags_list,
            search=search,
            page=page,
            size=size
        )
        
        return files
        
    except Exception as e:
        app_logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")

@router.get("/{file_id}", response_model=FileResponse)
async def get_file(
    file_id: str,
    file_service: FileService = Depends(get_file_service)
):
    """
    è·å–æ–‡ä»¶è¯¦æƒ…
    """
    try:
        file_record = file_service.get_file_by_id(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        return file_record
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥: {str(e)}")

@router.get("/{file_id}/download")
async def download_file(
    file_id: str,
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    ä¸‹è½½æ–‡ä»¶
    """
    try:
        # è·å–æ–‡ä»¶è®°å½•
        file_record = file_service.get_file_by_id(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä»æœ¬åœ°å­˜å‚¨è·å–æ–‡ä»¶ - æ³¨æ„ï¼šè¿™é‡Œä¸è¦ä½¿ç”¨awaitï¼Œå› ä¸ºdownload_fileè¿”å›çš„æ˜¯AsyncIterator
        file_data = storage_service.download_file(
            object_name=file_record.stored_name
        )
        
        # æ›´æ–°ä¸‹è½½æ¬¡æ•°
        file_service.increment_download_count(file_id)
        
        # å¤„ç†æ–‡ä»¶åç¼–ç é—®é¢˜
        import urllib.parse
        encoded_filename = urllib.parse.quote(file_record.original_name.encode('utf-8'))
        
        return StreamingResponse(
            file_data,
            media_type=file_record.file_type,
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}")

@router.get("/{file_id}/preview")
async def preview_file(
    file_id: str,
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    é¢„è§ˆæ–‡ä»¶
    """
    try:
        # è·å–æ–‡ä»¶è®°å½•
        file_record = await file_service.get_file_by_id(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä»æœ¬åœ°å­˜å‚¨è·å–æ–‡ä»¶
        file_data = await storage_service.download_file(
            object_name=file_record.stored_name
        )
        
        # æ›´æ–°æŸ¥çœ‹æ¬¡æ•°
        await file_service.increment_view_count(file_id)
        
        return StreamingResponse(
            file_data,
            media_type=file_record.file_type,
            headers={
                "Content-Disposition": f"inline; filename={file_record.original_name}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"æ–‡ä»¶é¢„è§ˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶é¢„è§ˆå¤±è´¥: {str(e)}")

@router.put("/{file_id}", response_model=FileResponse)
async def update_file(
    file_id: str,
    file_update: FileUpdate,
    file_service: FileService = Depends(get_file_service)
):
    """
    æ›´æ–°æ–‡ä»¶ä¿¡æ¯
    """
    try:
        file_record = file_service.update_file(file_id, file_update)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        return file_record
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}")

@router.delete("/{file_id}")
async def delete_file(
    file_id: str,
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    åˆ é™¤æ–‡ä»¶
    """
    try:
        # è·å–æ–‡ä»¶è®°å½•
        file_record = file_service.get_file_by_id(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä»æœ¬åœ°å­˜å‚¨åˆ é™¤æ–‡ä»¶
        await storage_service.delete_file(
            object_name=file_record.stored_name
        )
        
        # ä»å‘é‡æ•°æ®åº“åˆ é™¤åµŒå…¥å‘é‡
        try:
            from app.services.ai_service import ai_service
            vector_deleted = await ai_service.remove_document_from_vector_db(file_id)
            if vector_deleted:
                app_logger.info(f"ğŸ¤– æ–‡ä»¶å‘é‡å·²ä»å‘é‡æ•°æ®åº“åˆ é™¤: {file_record.original_name}")
            else:
                app_logger.warning(f"ğŸ¤– æ–‡ä»¶å‘é‡åˆ é™¤å¤±è´¥: {file_record.original_name}")
        except Exception as vector_error:
            app_logger.error(f"ğŸ¤– åˆ é™¤æ–‡ä»¶å‘é‡æ—¶å‡ºé”™: {vector_error}")
        
        # ä»æ•°æ®åº“åˆ é™¤è®°å½•
        file_service.delete_file(file_id)
        
        app_logger.info(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {file_record.original_name}")
        
        return {"message": "æ–‡ä»¶åˆ é™¤æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {str(e)}")

@router.post("/{file_id}/extract-content")
async def extract_file_content(
    file_id: str,
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    æå–æ–‡ä»¶å†…å®¹ï¼ˆç”¨äºAIåˆ†æï¼‰
    """
    try:
        # è·å–æ–‡ä»¶è®°å½•
        file_record = await file_service.get_file_by_id(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä»æœ¬åœ°å­˜å‚¨è·å–æ–‡ä»¶
        file_data = await storage_service.download_file(
            object_name=file_record.stored_name
        )
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹æå–å†…å®¹
        content = await file_service.extract_content(file_data, file_record.file_type)
        
        # æ›´æ–°æ–‡ä»¶å†…å®¹åˆ°æ•°æ®åº“
        await file_service.update_file_content(file_id, content)
        
        return {"message": "å†…å®¹æå–æˆåŠŸ", "content_length": len(content)}
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"å†…å®¹æå–å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹æå–å¤±è´¥: {str(e)}")

@router.get("/stats/summary")
async def get_file_stats(
    file_service: FileService = Depends(get_file_service)
):
    """
    è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        stats = file_service.get_file_stats()
        return {"message": "è·å–ç»Ÿè®¡ä¿¡æ¯æˆåŠŸ", "data": stats}
        
    except Exception as e:
        app_logger.error(f"è·å–æ–‡ä»¶ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶ç»Ÿè®¡å¤±è´¥: {str(e)}")

@router.post("/batch-index")
async def batch_index_files(
    project_id: Optional[str] = None,
    force_reindex: bool = False,
    file_service: FileService = Depends(get_file_service),
    storage_service: LocalFileService = Depends(get_storage_service)
):
    """
    æ‰¹é‡ç´¢å¼•æ–‡ä»¶åˆ°å‘é‡æ•°æ®åº“
    
    Args:
        project_id: é¡¹ç›®IDï¼Œå¦‚æœæŒ‡å®šåˆ™åªç´¢å¼•è¯¥é¡¹ç›®çš„æ–‡ä»¶
        force_reindex: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç´¢å¼•å·²å¤„ç†çš„æ–‡ä»¶
    """
    try:
        from app.services.ai_service import ai_service
        
        # è·å–éœ€è¦ç´¢å¼•çš„æ–‡ä»¶
        if project_id:
            files = file_service.get_files_by_project(project_id)
        else:
            files = file_service.get_all_unprocessed_files() if not force_reindex else file_service.get_all_files()
        
        app_logger.info(f"ğŸ¤– å¼€å§‹æ‰¹é‡ç´¢å¼•ï¼Œå…± {len(files)} ä¸ªæ–‡ä»¶")
        
        indexed_count = 0
        failed_count = 0
        
        for file_record in files:
            try:
                # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶ï¼ˆé™¤éå¼ºåˆ¶é‡æ–°ç´¢å¼•ï¼‰
                if file_record.is_processed and not force_reindex:
                    continue
                
                app_logger.info(f"ğŸ¤– æ­£åœ¨ç´¢å¼•æ–‡ä»¶: {file_record.original_name}")
                
                # ä»å­˜å‚¨è·å–æ–‡ä»¶æ•°æ®
                file_data = await storage_service.download_file(
                    object_name=file_record.stored_name
                )
                
                # æå–æ–‡ä»¶å†…å®¹
                content = await file_service.extract_content(file_data, file_record.file_type)
                
                if content and content.strip():
                    # æ›´æ–°æ–‡ä»¶å†…å®¹åˆ°æ•°æ®åº“
                    await file_service.update_file_content(file_record.id, content)
                    
                    # ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
                    metadata = {
                        "file_id": file_record.id,
                        "project_id": file_record.project_id,
                        "file_name": file_record.original_name,
                        "file_type": file_record.file_type,
                        "stage": file_record.stage,
                        "tags": file_record.tags or [],
                        "upload_time": file_record.created_at.isoformat() if file_record.created_at else datetime.now().isoformat(),
                        "content_length": len(content)
                    }
                    
                    document_id = f"file_{file_record.id}"
                    success = await ai_service.add_document_to_vector_db(
                        content=content,
                        file_id=file_record.id,
                        file_name=file_record.original_name,
                        project_id=file_record.project_id,
                        metadata=metadata
                    )
                    
                    if success:
                        # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
                        file_service.mark_file_processed(file_record.id)
                        indexed_count += 1
                        app_logger.info(f"ğŸ¤– æ–‡ä»¶ç´¢å¼•æˆåŠŸ: {file_record.original_name}")
                    else:
                        failed_count += 1
                        app_logger.warning(f"ğŸ¤– æ–‡ä»¶ç´¢å¼•å¤±è´¥: {file_record.original_name}")
                else:
                    app_logger.warning(f"ğŸ¤– æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ç´¢å¼•: {file_record.original_name}")
                    
            except Exception as file_error:
                failed_count += 1
                app_logger.error(f"ğŸ¤– å¤„ç†æ–‡ä»¶å¤±è´¥: {file_record.original_name}, é”™è¯¯: {str(file_error)}")
        
        app_logger.info(f"ğŸ¤– æ‰¹é‡ç´¢å¼•å®Œæˆï¼ŒæˆåŠŸ: {indexed_count}, å¤±è´¥: {failed_count}")
        
        return {
            "message": "æ‰¹é‡ç´¢å¼•å®Œæˆ",
            "indexed_count": indexed_count,
            "failed_count": failed_count,
            "total_processed": indexed_count + failed_count
        }
        
    except Exception as e:
        app_logger.error(f"æ‰¹é‡ç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ç´¢å¼•å¤±è´¥: {str(e)}")

@router.get("/search-context")
async def search_file_context(
    query: str,
    project_id: Optional[str] = None,
    limit: int = 5
):
    """
    æœç´¢æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼ˆç”¨äºAIé—®ç­”ï¼‰
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        project_id: é¡¹ç›®IDç­›é€‰
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
    """
    try:
        from app.services.ai_service import AIService
        ai_service = AIService()
        
        # æœç´¢ç›¸ä¼¼æ–‡æ¡£
        results = await ai_service.search_similar_documents(
            query=query,
            n_results=limit
        )
        
        # è¿‡æ»¤é¡¹ç›®ç›¸å…³ç»“æœ
        if project_id:
            results = [
                result for result in results
                if result.get('metadata', {}).get('project_id') == project_id
            ]
        
        return {
            "message": "æœç´¢å®Œæˆ",
            "query": query,
            "project_id": project_id,
            "results": results
        }
        
    except Exception as e:
        app_logger.error(f"æœç´¢æ–‡ä»¶ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœç´¢æ–‡ä»¶ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}") 